{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math, csv\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset():\n",
    "    test_x_file_raw = pd.read_csv(\"/Users/Marty/Documents/BMKT670/WedgeNeuralNet/test_inputs.csv\")\n",
    "    test_y_file_raw = pd.read_csv(\"/Users/Marty/Documents/BMKT670/WedgeNeuralNet/test_outputs.csv\")\n",
    "    train_x_file_raw = pd.read_csv(\"/Users/Marty/Documents/BMKT670/WedgeNeuralNet/train_inputs.csv\")\n",
    "    train_y_file_raw = pd.read_csv(\"/Users/Marty/Documents/BMKT670/WedgeNeuralNet/train_outputs.csv\")\n",
    "    \n",
    "    del(test_x_file_raw['Unnamed: 0'])\n",
    "    del(test_y_file_raw['Unnamed: 0'])\n",
    "    del(train_x_file_raw['Unnamed: 0'])\n",
    "    del(train_y_file_raw['Unnamed: 0'])\n",
    "    \n",
    "    train_set_x_orig = train_x_file_raw.as_matrix() # train set features\n",
    "    train_set_y_orig = train_y_file_raw.as_matrix() # train set labels\n",
    "\n",
    "    test_set_x_orig = test_x_file_raw.as_matrix() # test set features\n",
    "    test_set_y_orig = test_y_file_raw.as_matrix() # test set labels\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    X = tf.placeholder(\"float\", [n_x, None])\n",
    "    Y = tf.placeholder(\"float\", [n_y, None])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [10, 18]\n",
    "                        b1 : [10, 1]\n",
    "                        W2 : [6, 10]\n",
    "                        b2 : [6, 1]\n",
    "                        W3 : [1, 6]\n",
    "                        b3 : [1, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [10,18], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable(\"b1\", [10,1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [6,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable(\"b2\", [6,1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,6], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 128, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing actual spend in January 2017), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> Output\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                  # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.square(Z3 - Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 256, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 18, number of training examples = 18395)\n",
    "    Y_train -- test set, of shape (output size = 1, number of training examples = 18395)\n",
    "    X_test -- training set, of shape (input size = 18, number of training examples = 1250)\n",
    "    Y_test -- test set, of shape (output size = 1, number of test examples = 1250)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Uses an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        Variance = Z3 - Y\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(Variance, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> Output\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3\n",
    "    \n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [18, 1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = z3\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 18395\n",
      "number of test examples = 1250\n",
      "X_train shape: (18, 18395)\n",
      "Y_train shape: (1, 18395)\n",
      "X_test shape: (18, 1250)\n",
      "Y_test shape: (1, 1250)\n",
      "X = Tensor(\"Placeholder_3:0\", shape=(18, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_4:0\", shape=(1, ?), dtype=float32)\n",
      "W1 = Tensor(\"W1/read:0\", shape=(10, 18), dtype=float32)\n",
      "b1 = Tensor(\"b1/read:0\", shape=(10, 1), dtype=float32)\n",
      "W2 = Tensor(\"W2/read:0\", shape=(6, 10), dtype=float32)\n",
      "b2 = Tensor(\"b2/read:0\", shape=(6, 1), dtype=float32)\n",
      "Z3 = Tensor(\"Add_2:0\", shape=(1, ?), dtype=float32)\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I use this section to test to make sure the dimenions of my matrices are correct\n",
    "'''\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset()\n",
    "\n",
    "X_train = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "Y_train = Y_train_orig.reshape(Y_train_orig.shape[0], -1).T\n",
    "Y_test = Y_test_orig.reshape(Y_test_orig.shape[0], -1).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "X, Y = create_placeholders(18, 1)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(18, 1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(18, 1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 377134.267496\n",
      "Cost after epoch 100: 109924.673278\n",
      "Cost after epoch 200: 27495.914104\n",
      "Cost after epoch 300: 23978.190457\n",
      "Cost after epoch 400: 22268.338537\n",
      "Cost after epoch 500: 21233.831866\n",
      "Cost after epoch 600: 20474.584535\n",
      "Cost after epoch 700: 19960.832086\n",
      "Cost after epoch 800: 19470.416483\n",
      "Cost after epoch 900: 19266.948531\n",
      "Cost after epoch 1000: 18928.920995\n",
      "Cost after epoch 1100: 18856.693621\n",
      "Cost after epoch 1200: 18664.524510\n",
      "Cost after epoch 1300: 18556.274792\n",
      "Cost after epoch 1400: 18415.671146\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsnOwMTOzsvv/AfsM/BZcYKXlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e359cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: -1.60647\n",
      "Test Accuracy: -1.67369\n"
     ]
    }
   ],
   "source": [
    "'''RUN THE NEURAL NETWORK'''\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35.53  51.68  33.95  73.42  14.59   4.27  12.56  10.1   13.83   0.97\n",
      "   61.86   5.77  19.3   16.91  12.     3.2   73.84  13.24]]\n",
      "2010 - 2016 Avg. January Spend of $457.02\n",
      "Estimated 2017 January spend of $467.99\n",
      "\n",
      " \n",
      "\n",
      "[[ 29.2   85.29   5.47  21.98   1.47   2.79   0.86  11.8   13.23   2.18\n",
      "   17.04  30.54  47.98  23.48   1.93   1.98  43.55  50.55]]\n",
      "2010 - 2016 Avg. January Spend of $391.32\n",
      "Estimated 2017 January spend of $559.75\n",
      "\n",
      " \n",
      "\n",
      "[[ 88.16   3.76  78.16  52.87   5.65  15.44   0.09  39.13  36.33  14.87\n",
      "   12.47  19.32  12.95   1.19  66.22  17.35   2.9   28.56]]\n",
      "2010 - 2016 Avg. January Spend of $495.42\n",
      "Estimated 2017 January spend of $67.29\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate three random test arrays\n",
    "Run through the predictive model\n",
    "\"\"\"\n",
    "test_array1 = np.random.randint(0,50,(18,1))*np.absolute(np.random.randn(18,1))\n",
    "test_array2 = np.random.randint(0,50,(18,1))*np.absolute(np.random.randn(18,1))\n",
    "test_array3 = np.random.randint(0,50,(18,1))*np.absolute(np.random.randn(18,1))\n",
    "image1 = test_array1.round(2)\n",
    "image1 = image1.reshape(18,1) #Have to reshape to fit the model\n",
    "my_image_prediction1 = predict(image1, parameters)\n",
    "image2 = test_array2.round(2)\n",
    "image2 = image2.reshape(18,1)\n",
    "my_image_prediction2 = predict(image2, parameters)\n",
    "image3 = test_array3.round(2)\n",
    "image3 = image3.reshape(18,1)\n",
    "my_image_prediction3 = predict(image3, parameters)\n",
    "\n",
    "# Print the results\n",
    "print(image1.reshape(1,18))\n",
    "print(\"2010 - 2016 Avg. January Spend of $\" + str(round(sum(np.squeeze(image1)), 2)))\n",
    "print(\"Estimated 2017 January spend of $\" + str(np.squeeze(my_image_prediction1).round(2)))\n",
    "print(\"\\n \\n\")\n",
    "print(image2.reshape(1,18))\n",
    "print(\"2010 - 2016 Avg. January Spend of $\" + str(round(sum(np.squeeze(image2)), 2)))\n",
    "print(\"Estimated 2017 January spend of $\" + str(np.squeeze(my_image_prediction2).round(2)))\n",
    "print(\"\\n \\n\")\n",
    "print(image3.reshape(1,18))\n",
    "print(\"2010 - 2016 Avg. January Spend of $\" + str(round(sum(np.squeeze(image3)), 2)))\n",
    "print(\"Estimated 2017 January spend of $\" + str(np.squeeze(my_image_prediction3).round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
